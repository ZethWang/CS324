### 图片内容翻译

#### 图片一

在本讲座中，我们将探索 GPT-3，这个典型的大型语言模型的能力。我们将紧密跟随 GPT-3 论文中的基准测试，包括：

- 标准 NLP 基准测试（例如，问答），以及
- 一次性演示（例如，在句子中使用一个新词）。

与每个任务的最新技术结果相比，结果是混合的：

- 在某些任务上，如语言建模，GPT-3 以巨大优势超越了最新技术。
- 在其他任务上，GPT-3 需要与使用大量标注数据训练的系统竞争，结果落后很多。

考虑这些结果的方法如下：

- GPT-3 并未明确针对这些任务进行训练；它只是被训练为一个语言模型来预测下一个词。
- 尽管如此，即使在没有“尝试”的情况下，GPT-3 在广泛的 NLP 任务上也能做得相当不错。
- 由于 GPT-3 并未针对这些任务进行训练，它没有过拟合，这意味着它有很大的机会在许多其他任务上表现良好（如在一次性任务上的可接受表现所示）。
- 此外，如果您希望在任何特定任务（例如，问答）上表现良好，原则上您应该能够使用大量标注数据来适应 GPT-3，从而超越最新技术。

#### 图片二

**适应**。请记住，语言模型 \( p \) 是在一系列标记 \( x_{1:L} \) 上的分布，因此可以用于对序列进行评分：

\[ p(\text{the, mouse, ate, the, cheese}) \]

它也可以用于执行条件生成，给定一个提示生成一个补全：

\[ \text{the mouse ate} \Rightarrow \text{the cheese} \]

一个任务是从输入到输出的映射。例如，对于问答，我们可能有：

```
输入：Burne Hogarth 建立了哪所学校？
输出：视觉艺术学院
```

我们使用“适应”这个术语来指代将语言模型转换为任务模型的过程，给定：

- 任务的自然语言描述，以及
- 一组训练实例（输入-输出对）。

有两种主要的方法来执行适应：

1. **训练（标准监督学习）**：训练一个新的模型，将输入映射到输出，可以通过以下方式：
   - 创建一个新模型，使用语言模型作为特征（探测）；
   - ![Alt text](image-6.png)
   - 以语言模型为起点，基于训练实例进行更新（微调）；或
   - 两者之间的某种轻量级微调。

2. **提示（上下文学习）**：构建一个提示（基于描述和训练实例的字符串），或一组提示，将它们馈入语言模型以获得补全。

#### 图片三

我们应该选择哪种适应程序？

- 训练可能因过拟合而具有挑战性（只需想象对 1750 亿参数模型进行微调，仅基于 5 个示例）。如何有效地进行这一操作将是适应讲座的主题。
- 目前，我们将满足于使用提示对 GPT-3 进行适应。请注意，提示的限制在于我们只能利用少量的训练实例（尽可能多地放入提示中）。这是由于 Transformer 的限制，提示和补全必须适合 2048 个标记。

GPT-3 论文在大量任务上评估了 GPT-3。我们将考虑其中的一部分，并针对每个任务讨论以下内容：

1. **定义**：任务是什么及其动机？
2. **适应**：我们如何通过提示将任务简化为语言建模？
3. **结果**：与任务特定的最新技术模型相比，定量结果如何？

#### 图片四

任务分组如下：

1. 语言建模
2. 问答
3. 翻译
4. 算术
5. 新闻文章生成
6. 新奇任务

本讲座的目标是提供：

1. 对 NLP 任务的概述（独立于大型语言模型），
2. 对 GPT-3 工作情况的了解，以及
3. 对提示工程艺术的品味。



### 图片内容翻译

#### 图片一

**大小和样本数量的重要性**。默认情况下，结果将基于以下内容：

- 完整的 GPT-3 模型（davinci），具有 1750 亿个参数。
- 使用尽可能多的上下文学习训练实例填充提示。

在此过程中，我们将进行消融实验，以确定模型大小和上下文训练实例数量是否重要。剧透：确实重要，而且越多越好。

任务分组如下：

1. 语言建模
2. 问答
3. 翻译
4. 算术
5. 新闻文章生成
6. 新奇任务

本讲座的目标是提供：

1. 对 NLP 任务的概述（独立于大型语言模型），
2. 对 GPT-3 工作情况的了解，以及
3. 对提示工程艺术的品味。

#### 图片二

**语言建模**

思考语言模型的能力最自然的起点是问它是否能够完成语言模型应该做的事情：建模语言。

回想一下，语言模型 \( p \) 是在一系列标记 \( x_{1:L} \) 上的概率分布。假设我们有一个文本语料库 \( x_{1:L} \)，例如：

\[ \text{the mouse ate the cheese} \]

我们可以问：语言模型赋予它的概率是多少？

\[ p(\text{the mouse ate the cheese}) \]

回想一下，我们可以通过链式法则将联合概率分解为每个标记的条件概率的乘积：

\[ p(x_{1:L}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}) \]

**困惑度**。序列的联合概率取决于其长度，因此随着长度的增加会趋于零，这使得它难以跟踪。（试想通过获取更多新闻线来更好地估计新闻线的困惑度。）

直观上，我们希望平均每个标记的概率 \( p(x_i \mid x_{1:i-1}) \)。我们不想取算术平均，因为将标记分配为0概率确实很糟糕（想想编码：你的代码长度将是无限的），但算术平均不会因为没有惩罚你而惩罚你。取而代之的是，我们希望取几何平均，这正是困惑度的作用：

\[ \text{perplexity}_p(x_{1:L}) = \exp \left( \frac{1}{L} \sum_{i=1}^L \log \frac{1}{p(x_i \mid x_{1:i-1})} \right) \]

困惑度可以解释为每个标记的平均“分支因子”。回想一下， \( \log \frac{1}{p(x_i \mid x_{1:i-1})} \) 是代码长度。我们取平均代码长度；指数化提供了可能性的数量。为了直观理解，取均匀分布：长度为3的位串可以编码 \( 2^3 \) 个可能字符串。

#### 图片三

**两种错误的故事**。语言模型可以犯两种错误，而困惑度不对称地对待它们：

1. **召回错误**：语言模型未能在某个标记上放置概率质量。困惑度没有怜悯：

\[ p(\text{ate} \mid \text{the, mouse}) \rightarrow 0 \Rightarrow \text{perplexity}_p(\text{the, mouse, ate, the, cheese}) \rightarrow \infty \]

2. **精度错误**：语言模型在一些不良序列上放置了额外的概率质量。困惑度提供了一个小小的惩罚。给定一个语言模型 \( p \)，假设我们以概率 \( \epsilon \) 混入了一些垃圾分布 \( r \)：

\[ q(x_i \mid x_{1:i-1}) = (1 - \epsilon)p(x_i \mid x_{1:i-1}) + \epsilon r(x_i \mid x_{1:i-1}) \]

然后我们可以计算 \( x_{1:L} \) 在 \( q \) 下的困惑度：

\[ \text{perplexity}_q(x_{1:L}) \leq \frac{1}{1 - \epsilon} \text{perplexity}_p(x_{1:L}) \approx (1 + \epsilon) \text{perplexity}_p(x_{1:L}) \]

最后的近似等式在小值 \( \epsilon \) 时成立。如果我们混入 5% 的垃圾，那么困惑度只会增加约 5%。注意，由于每 20 个标记中平均只有 1 个是垃圾，生成的语言实际上很糟糕。

#### 图片四

**Penn Tree Bank**

Penn Tree Bank 是 NLP 中的经典数据集，最初用于句法解析。从 Emami 和 Jelinek（2004）以及 Mikolov 和 Zweig（2012）开始，使用仅包含华尔街日报文章的版本作为语言建模评估数据集。请注意，PTB 语言建模基准测试涉及对原始数据集进行一些显著的预处理（感谢 John Hewitt 指出这一点）。

**适应**。将整个文本作为提示输入 GPT-3 并评估困惑度（演示）：

```
Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29. Mr. Vinken is chairman of Elsevier N.V., the Dutch publishing group.
```

**结果**。GPT-3 远远超越了现有的最新技术：

| 模型            | 困惑度 |
|----------------|--------|
| GPT-3          | 20.5   |
| BERT-Large-CAs1 | 31.3   |

有关最新结果，请参见排行榜。

**训练/测试泄露**。作者没有在某些数据集（如 WikiText-103）上进行评估，因为 GPT-3 在 Wikipedia 上进行了训练。PTB 的优势在于其早于互联网出现，并且仅通过付费许可证提供。这是大数据集的另一个复杂性：很难检查你的测试数据没有出现在训练数据中并被记住。


### 困惑度 (Perplexity) 详解

#### 什么是困惑度？

困惑度是衡量语言模型性能的一个常用指标，反映了模型对给定序列的预测准确性。具体来说，困惑度是模型在预测下一个标记时面临的不确定性程度。

#### 公式及解释

给定一个序列 \( x_{1:L} \)，困惑度定义如下：

\[ \text{perplexity}_p(x_{1:L}) = \exp \left( \frac{1}{L} \sum_{i=1}^L \log \frac{1}{p(x_i \mid x_{1:i-1})} \right) \]

这个公式表示的是每个标记的平均“分支因子”：

- \(\frac{1}{p(x_i \mid x_{1:i-1})}\) 表示的是对标记 \( x_i \) 的预测反转后的概率（也就是标记出现的可能性越小，反转后的值越大）。
- \(\log \frac{1}{p(x_i \mid x_{1:i-1})}\) 是编码长度。困惑度取的是平均编码长度，并通过取指数化来转换为可能性的数量。

**直观解释**：
- 困惑度越小，表示模型对序列的预测越准确。
- 困惑度越大，表示模型对序列的预测越不确定。

举例说明：
假设一个模型预测一个三字符长度的位串（每个字符均匀分布），则这个位串的可能性为 \( 2^3 \)，表示有8种可能的字符串。如果模型能准确预测每个字符，则困惑度越小。

#### 困惑度和交叉熵的关系

交叉熵 \( H(p, q) \) 衡量的是用模型 \( q \) 来表示真实分布 \( p \) 的样本所需的平均比特数，其公式如下：

\[ H(p, q) = \sum_x p(x) \log \frac{1}{q(x)} \]

对于语言模型，交叉熵可以写成：

\[ H(p) = - \frac{1}{L} \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \]

困惑度则是交叉熵的指数：

\[ \text{perplexity} = \exp(H(p)) \]

也就是说，困惑度实际上是交叉熵的指数形式，用于直观地表示模型的不确定性。

#### 两者的联系

- 交叉熵提供了编码长度的平均度量，困惑度将其转换为更直观的可能性数量。
- 两者都用于评估模型的预测能力，但困惑度在语言模型的实际应用中更为常见，因为它提供了更直观的解读。

### 总结

- 困惑度是衡量语言模型预测能力的不确定性程度，数值越小表示模型性能越好。
- 交叉熵衡量的是模型对真实分布的平均编码长度。
- 困惑度是交叉熵的指数形式，便于直观理解和比较模型性能。

希望这个解释能帮助你更好地理解困惑度及其与交叉熵的关系。如果还有任何问题，请告诉我！



这个公式的解释涉及到语言模型中的交叉熵计算。我们将一步步解释为什么对于语言模型，交叉熵可以写成：

\[ H(p) = - \frac{1}{L} \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \]

### 交叉熵的基本概念

交叉熵 \( H(p, q) \) 衡量的是使用模型 \( q \) 来表示真实分布 \( p \) 的样本所需的平均比特数。其公式为：

\[ H(p, q) = \sum_x p(x) \log \frac{1}{q(x)} \]

当 \( p = q \) 时，交叉熵就是熵：

\[ H(p) = \sum_x p(x) \log \frac{1}{p(x)} \]

### 语言模型中的交叉熵

在语言模型中，我们希望计算的是序列的交叉熵。一个序列 \( x_{1:L} \) 可以被看作是一系列标记的联合分布：

\[ p(x_{1:L}) = p(x_1, x_2, \ldots, x_L) \]

通过链式法则，这个联合分布可以分解为条件概率的乘积：

\[ p(x_{1:L}) = p(x_1) \cdot p(x_2 \mid x_1) \cdot p(x_3 \mid x_1, x_2) \cdots p(x_L \mid x_1, x_2, \ldots, x_{L-1}) \]

更一般地，可以写成：

\[ p(x_{1:L}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}) \]

因此，计算序列 \( x_{1:L} \) 的概率实际上是计算每个标记给定其之前的标记序列的条件概率的乘积。

### 交叉熵的具体计算

对于序列 \( x_{1:L} \)，其交叉熵的计算公式为：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \log p(x_{1:L}) \]

我们使用链式法则分解 \( p(x_{1:L}) \)：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \log \left( \prod_{i=1}^L p(x_i \mid x_{1:i-1}) \right) \]

由于对数的性质（对数乘积等于乘积对数），我们可以将其展开为：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \]

交换求和顺序：

\[ H(p) = - \sum_{i=1}^L \sum_{x_{1:L}} p(x_{1:L}) \log p(x_i \mid x_{1:i-1}) \]

因为我们是对所有可能的序列 \( x_{1:L} \) 求和，并且 \( p(x_{1:L}) \) 是一个概率分布，所以对于每个 \( i \) 来说，这个内部求和实际上就是对 \( x_i \mid x_{1:i-1} \) 的条件分布求和，即：

\[ H(p) = - \sum_{i=1}^L \mathbb{E}_{x_{1:i-1}} [ \log p(x_i \mid x_{1:i-1}) ] \]

对于一个固定长度为 \( L \) 的序列，我们取平均值：

\[ H(p) = - \frac{1}{L} \sum_{i=1}^L \mathbb{E}_{x_{1:i-1}} [ \log p(x_i \mid x_{1:i-1}) ] \]

这就是公式 \( H(p) = - \frac{1}{L} \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \) 的由来。

### 结论

这个公式说明了对于语言模型来说，交叉熵可以看作是所有条件概率的对数的负平均值。这意味着我们在计算语言模型的交叉熵时，实际上是在计算每个标记的条件概率，并取其对数的负平均值。这样做能够有效衡量模型对整个序列的预测能力。

### 交叉熵解释及示例

为了更好地理解交叉熵，尤其是它在语言模型中的应用，我们先从基本概念开始，再通过一个具体的例子进行说明。

#### 基本概念

交叉熵 \( H(p, q) \) 衡量的是用模型 \( q \) 来表示真实分布 \( p \) 的样本所需的平均比特数。其公式为：

\[ H(p, q) = \sum_x p(x) \log \frac{1}{q(x)} \]

对于语言模型，我们通常会计算序列的交叉熵。一个序列 \( x_{1:L} \) 可以被看作是一系列标记的联合分布：

\[ p(x_{1:L}) = p(x_1, x_2, \ldots, x_L) \]

通过链式法则，这个联合分布可以分解为条件概率的乘积：

\[ p(x_{1:L}) = p(x_1) \cdot p(x_2 \mid x_1) \cdot p(x_3 \mid x_1, x_2) \cdots p(x_L \mid x_1, x_2, \ldots, x_{L-1}) \]

更一般地，可以写成：

\[ p(x_{1:L}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}) \]

#### 交叉熵的具体计算

对于序列 \( x_{1:L} \)，其交叉熵的计算公式为：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \log p(x_{1:L}) \]

我们使用链式法则分解 \( p(x_{1:L}) \)：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \log \left( \prod_{i=1}^L p(x_i \mid x_{1:i-1}) \right) \]

由于对数的性质（对数乘积等于乘积对数），我们可以将其展开为：

\[ H(p) = - \sum_{x_{1:L}} p(x_{1:L}) \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \]

交换求和顺序：

\[ H(p) = - \sum_{i=1}^L \sum_{x_{1:L}} p(x_{1:L}) \log p(x_i \mid x_{1:i-1}) \]

因为我们是对所有可能的序列 \( x_{1:L} \) 求和，并且 \( p(x_{1:L}) \) 是一个概率分布，所以对于每个 \( i \) 来说，这个内部求和实际上就是对 \( x_i \mid x_{1:i-1} \) 的条件分布求和，即：

\[ H(p) = - \sum_{i=1}^L \mathbb{E}_{x_{1:i-1}} [ \log p(x_i \mid x_{1:i-1}) ] \]

对于一个固定长度为 \( L \) 的序列，我们取平均值：

\[ H(p) = - \frac{1}{L} \sum_{i=1}^L \mathbb{E}_{x_{1:i-1}} [ \log p(x_i \mid x_{1:i-1}) ] \]

这就是公式 \( H(p) = - \frac{1}{L} \sum_{i=1}^L \log p(x_i \mid x_{1:i-1}) \) 的由来。

### 示例

假设我们有一个简化的文本数据集，仅包含以下三个序列：

1. "a b c"
2. "a b d"
3. "a e f"

我们希望计算这些序列的交叉熵。我们假设真实分布 \( p \) 和模型分布 \( q \) 如下：

- \( p \)：
  - \( p(a) = 1 \)（因为每个序列都以 "a" 开头）
  - \( p(b \mid a) = 2/3, p(e \mid a) = 1/3 \)
  - \( p(c \mid a, b) = 1/2, p(d \mid a, b) = 1/2 \)
  - \( p(f \mid a, e) = 1 \)

- \( q \)：
  - \( q(a) = 1 \)
  - \( q(b \mid a) = 1/2, q(e \mid a) = 1/2 \)
  - \( q(c \mid a, b) = 1/2, q(d \mid a, b) = 1/2 \)
  - \( q(f \mid a, e) = 1 \)

现在计算交叉熵：

\[ H(p, q) = - \sum_{x_{1:L}} p(x_{1:L}) \log q(x_{1:L}) \]

具体步骤如下：

1. 对于 "a b c"：
   - \( p(a b c) = p(a) \cdot p(b \mid a) \cdot p(c \mid a, b) = 1 \cdot \frac{2}{3} \cdot \frac{1}{2} = \frac{1}{3} \)
   - \( q(a b c) = q(a) \cdot q(b \mid a) \cdot q(c \mid a, b) = 1 \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4} \)
   - 对数部分： \( \log q(a b c) = \log \frac{1}{4} = -2 \)

2. 对于 "a b d"：
   - \( p(a b d) = p(a) \cdot p(b \mid a) \cdot p(d \mid a, b) = 1 \cdot \frac{2}{3} \cdot \frac{1}{2} = \frac{1}{3} \)
   - \( q(a b d) = q(a) \cdot q(b \mid a) \cdot q(d \mid a, b) = 1 \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4} \)
   - 对数部分： \( \log q(a b d) = \log \frac{1}{4} = -2 \)

3. 对于 "a e f"：
   - \( p(a e f) = p(a) \cdot p(e \mid a) \cdot p(f \mid a, e) = 1 \cdot \frac{1}{3} \cdot 1 = \frac{1}{3} \)
   - \( q(a e f) = q(a) \cdot q(e \mid a) \cdot q(f \mid a, e) = 1 \cdot \frac{1}{2} \cdot 1 = \frac{1}{2} \)
   - 对数部分： \( \log q(a e f) = \log \frac{1}{2} = -1 \)

将所有部分加总：

\[ H(p, q) = - \left( \frac{1}{3} \cdot (-2) + \frac{1}{3} \cdot (-2) + \frac{1}{3} \cdot (-1) \right) \]

\[ H(p, q) = - \left( -\frac{2}{3} - \frac{2}{3} - \frac{1}{3} \right) = \frac{5}{3} \]

因此，这个简化示例中的交叉熵 \( H(p, q) = \frac{5}{3} \)。

### 结论

通过这个具体的例子，我们可以看到如何计算交叉熵，并理解它在衡量模型性能时的作用。交叉熵的核心在于它不仅考虑了真实分布的概率，还考虑了模型分布的对数概率，从而全面评估模型在实际应用中的表现。
### 两种错误的故事：召回错误与精度错误

在语言模型中，困惑度 (perplexity) 是衡量模型性能的一个重要指标。然而，困惑度对两种类型的错误有不同的反应：召回错误和精度错误。

#### 1. 召回错误 (Recall Error)

召回错误是指语言模型未能在某个标记上放置足够的概率质量。例如：

\[ p(\text{ate} \mid \text{the, mouse}) \rightarrow 0 \]

这意味着在给定前面标记“the, mouse”后，模型预测“ate”的概率接近于零。由于“ate”在这个上下文中是一个合理的词，但模型却赋予它极低的概率，这就是召回错误。

- **影响**：召回错误会导致困惑度无限大。因为困惑度公式中包含了对概率的对数，当概率接近零时，对数值将趋向负无穷，从而导致整个困惑度趋向无穷大。
- **解释**：困惑度对召回错误没有怜悯，因为当模型在一个合理的词上放置极低的概率时，困惑度会急剧增加，表示模型性能非常差。

#### 2. 精度错误 (Precision Error)

精度错误是指语言模型在一些不良序列上放置了过高的概率质量。例如：

给定一个语言模型 \( p \)，假设我们以概率 \( \epsilon \) 混入了一些垃圾分布 \( r \)，得到一个新的模型 \( q \)：

\[ q(x_i \mid x_{1:i-1}) = (1 - \epsilon)p(x_i \mid x_{1:i-1}) + \epsilon r(x_i \mid x_{1:i-1}) \]

这意味着在模型 \( q \) 中，我们在每个标记的条件概率上添加了一些噪声。

- **影响**：困惑度对精度错误提供了较小的惩罚。具体来说，如果我们混入 \( \epsilon \) 比例的噪声，那么困惑度的增加量约为 \( (1 + \epsilon) \) 倍。
- **解释**：与召回错误不同，精度错误导致的困惑度增加较为温和。因为即使混入了一些噪声，模型的整体预测能力仍然较为合理。

#### 具体计算

假设我们有一个模型 \( p \) 的困惑度为 \( \text{perplexity}_p(x_{1:L}) \)。当我们在模型 \( q \) 中混入比例为 \( \epsilon \) 的噪声后，困惑度的计算如下：

\[ \text{perplexity}_q(x_{1:L}) \leq \frac{1}{1 - \epsilon} \text{perplexity}_p(x_{1:L}) \approx (1 + \epsilon) \text{perplexity}_p(x_{1:L}) \]

这意味着如果我们混入了 5% 的噪声，那么困惑度只会增加约 5%。

### 总结

- **召回错误**：模型未能在合理的词上放置足够的概率质量，导致困惑度急剧增加。
- **精度错误**：模型在一些不合理的词上放置了过高的概率质量，导致困惑度温和增加。

困惑度对召回错误非常敏感，但对精度错误相对宽容。这使得困惑度在评估模型预测能力时，对召回错误有着更为严厉的惩罚，从而更准确地反映模型性能的优劣。

希望这个详细解释能帮助你更好地理解困惑度在语言模型评估中的作用。如果还有任何问题，请告诉我！


---
在分类任务中，精度、准确率和召回率是评估分类模型性能的重要指标。让我们详细解释这三个指标以及它们的计算方法和意义。

### 1. 精度（Precision）

**定义**: 精度（Precision）是指在模型预测为正类的所有样本中，实际为正类的比例。

**计算公式**:
\[ \text{精度} = \frac{\text{真正类（TP）}}{\text{真正类（TP）} + \text{假正类（FP）}} \]

**解释**:
- 真正类（True Positive, TP）：模型正确预测为正类的样本数。
- 假正类（False Positive, FP）：模型错误预测为正类的样本数。

精度关注的是预测为正类的样本中，有多少是正确的。高精度意味着模型预测为正类的样本大多数是正确的。

### 2. 准确率（Accuracy）

**定义**: 准确率（Accuracy）是指模型正确预测的样本数占总样本数的比例。

**计算公式**:
\[ \text{准确率} = \frac{\text{真正类（TP）} + \text{真负类（TN）}}{\text{总样本数（TP + TN + FP + FN）}} \]

**解释**:
- 真负类（True Negative, TN）：模型正确预测为负类的样本数。
- 假负类（False Negative, FN）：模型错误预测为负类的样本数。

准确率反映了模型整体预测的正确性，考虑了所有样本的预测结果。高准确率意味着模型在总体上预测较准确。

### 3. 召回率（Recall）

**定义**: 召回率（Recall）是指在实际为正类的所有样本中，被模型正确预测为正类的比例。

**计算公式**:
\[ \text{召回率} = \frac{\text{真正类（TP）}}{\text{真正类（TP）} + \text{假负类（FN）}} \]

**解释**:
- 假负类（False Negative, FN）：模型错误预测为负类的样本数。

召回率关注的是实际为正类的样本中，有多少被模型正确预测为正类。高召回率意味着模型能够识别出大多数的正类样本。

### 具体例子

假设我们有以下混淆矩阵（Confusion Matrix）：

|            | 预测正类 | 预测负类 |
|------------|----------|----------|
| 实际正类   | 50 (TP)  | 10 (FN)  |
| 实际负类   | 5 (FP)   | 100 (TN) |

- **精度**:
  \[ \text{精度} = \frac{50}{50 + 5} = \frac{50}{55} \approx 0.909 \]

- **准确率**:
  \[ \text{准确率} = \frac{50 + 100}{50 + 100 + 5 + 10} = \frac{150}{165} \approx 0.909 \]

- **召回率**:
  \[ \text{召回率} = \frac{50}{50 + 10} = \frac{50}{60} \approx 0.833 \]

### 总结

- **精度**: 关注模型预测为正类的样本中，有多少是正确的。
- **准确率**: 反映模型整体预测的正确性，考虑了所有样本的预测结果。
- **召回率**: 关注实际为正类的样本中，有多少被模型正确预测为正类。

这三个指标从不同角度评估模型的性能。在实际应用中，选择哪个指标作为主要评估标准取决于具体任务的需求。例如，在疾病检测中，召回率可能比精度更重要，因为我们希望尽可能多地识别出所有患病的患者。


### 详细解释 ROC 曲线

ROC 曲线（Receiver Operating Characteristic Curve，接收者操作特征曲线）是用于评估二分类模型性能的图形工具。它反映了模型在不同阈值下的分类能力。通过绘制假正例率（False Positive Rate, FPR）和真正例率（True Positive Rate, TPR）的变化关系，ROC 曲线展示了模型的整体表现。

#### 关键概念

1. **真正例率 (True Positive Rate, TPR)**:
   - 也称为召回率（Recall），灵敏度（Sensitivity）。
   - 计算公式：
     \[
     \text{TPR} = \frac{\text{真正类（TP）}}{\text{真正类（TP）} + \text{假负类（FN）}}
     \]
   - 表示的是实际为正类的样本中被正确预测为正类的比例。

2. **假正例率 (False Positive Rate, FPR)**:
   - 计算公式：
     \[
     \text{FPR} = \frac{\text{假正类（FP）}}{\text{假正类（FP）} + \text{真负类（TN）}}
     \]
   - 表示的是实际为负类的样本中被错误预测为正类的比例。

3. **阈值（Threshold）**:
   - 分类模型通常输出一个概率值，表示样本属于正类的概率。我们通过设置不同的阈值来决定将样本分类为正类还是负类。例如，若概率大于某一阈值时预测为正类，否则为负类。

### 绘制 ROC 曲线

ROC 曲线通过以下步骤绘制：

1. **选择不同的阈值**：从 0 到 1 之间选择一系列不同的阈值。
2. **计算 TPR 和 FPR**：对于每个阈值，计算相应的 TPR 和 FPR。
3. **绘制曲线**：以 FPR 为横坐标，TPR 为纵坐标，绘制 ROC 曲线。

### 示例

假设我们有一个二分类模型，输出的是样本属于正类的概率。我们通过以下数据绘制 ROC 曲线：

| 样本 | 实际标签 | 预测概率 |
|------|----------|----------|
| 1    | 1        | 0.9      |
| 2    | 0        | 0.8      |
| 3    | 1        | 0.7      |
| 4    | 0        | 0.6      |
| 5    | 1        | 0.5      |
| 6    | 0        | 0.4      |
| 7    | 1        | 0.3      |
| 8    | 0        | 0.2      |

#### 计算步骤

1. **选择阈值**：例如，选择阈值为 0.5。
2. **分类结果**：
   - 当阈值为 0.5 时，预测概率大于 0.5 的样本被分类为正类，其他为负类。
   - 分类结果为：样本 1, 2, 3, 4, 5 被预测为正类，样本 6, 7, 8 被预测为负类。

3. **计算混淆矩阵**：
   - 真正例（TP）：样本 1, 3, 5（实际为正类且预测为正类）。
   - 假正例（FP）：样本 2, 4（实际为负类但预测为正类）。
   - 真负例（TN）：样本 6, 8（实际为负类且预测为负类）。
   - 假负例（FN）：样本 7（实际为正类但预测为负类）。

4. **计算 TPR 和 FPR**：
   - TPR = \(\frac{3}{4} = 0.75\)
   - FPR = \(\frac{2}{4} = 0.5\)

5. **改变阈值，重复计算**：选择不同的阈值（如 0.4、0.6 等），重复上述步骤，计算不同阈值下的 TPR 和 FPR。

### ROC 曲线图解

1. **坐标系**：
   - 横轴：假正例率（FPR）
   - 纵轴：真正例率（TPR）

2. **绘制点**：
   - 根据不同阈值计算得到的 TPR 和 FPR 绘制点。

3. **连接点**：
   - 将各个点连接，形成 ROC 曲线。

### AUC（Area Under the Curve）

AUC 是 ROC 曲线下的面积，用于衡量模型的整体性能。AUC 的取值范围在 0 到 1 之间，值越大表示模型性能越好。

- AUC = 1：完美分类器。
- 0.5 < AUC < 1：比随机猜测好。
- AUC = 0.5：等同于随机猜测。
- AUC < 0.5：比随机猜测还差。

### 示例图解

假设我们有以下 TPR 和 FPR 的计算结果：

| 阈值 | TPR  | FPR  |
|------|------|------|
| 0.9  | 0.25 | 0    |
| 0.8  | 0.5  | 0.25 |
| 0.7  | 0.75 | 0.5  |
| 0.6  | 1    | 0.75 |
| 0.5  | 1    | 1    |

绘制 ROC 曲线，我们得到一个从 (0, 0) 点出发，到 (1, 1) 点的曲线，通过连接各个点（FPR, TPR）形成的曲线，这就是 ROC 曲线。

希望这个详细解释和示例能帮助你理解 ROC 曲线及其计算过程。如果还有任何问题，请告诉我。


### 选择假正例率（FPR）和真正例率（TPR）的原因

**假正例率 (False Positive Rate, FPR)** 和 **真正例率 (True Positive Rate, TPR)** 是评估分类模型性能的两个关键指标。选择这两个指标有以下原因：

1. **综合评估模型性能**：
   - **TPR**（真正例率）反映了模型对正类样本的识别能力，即模型能正确识别出多少正类样本。
   - **FPR**（假正例率）反映了模型对负类样本的误识别能力，即模型错误地将多少负类样本识别为正类。
   - 通过同时考察这两个指标，可以综合评估模型在识别正类和负类样本上的表现。

2. **平衡模型表现**：
   - 一个理想的模型应该有高的 TPR 和低的 FPR。高 TPR 表示模型对正类样本的识别能力强，低 FPR 表示模型对负类样本的误识别少。
   - 选择这两个指标，可以帮助我们权衡和调节模型在这两个方面的表现，从而达到更好的分类效果。

3. **不同阈值的影响**：
   - 分类模型通常基于概率来决定样本的类别，而这个概率阈值是可以调整的。
   - 不同的阈值会影响模型的 TPR 和 FPR。通过绘制 ROC 曲线，可以直观地看到在不同阈值下模型的表现，从而选择最佳阈值。

### FPR 和 TPR 与阈值的关系

分类模型输出的是样本属于正类的概率，通过设置不同的阈值来决定样本的分类结果。当我们调整阈值时，TPR 和 FPR 会发生变化。

- **低阈值**：更多的样本被预测为正类。
  - **TPR**：可能增加，因为更多的实际正类样本被正确识别。
  - **FPR**：也可能增加，因为更多的实际负类样本被错误识别为正类。

- **高阈值**：更少的样本被预测为正类。
  - **TPR**：可能减少，因为更多的实际正类样本被错误识别为负类。
  - **FPR**：也可能减少，因为更多的实际负类样本被正确识别为负类。

### 例子说明

假设我们有一个二分类问题，通过调整不同的阈值来观察 TPR 和 FPR 的变化。以下是一个简单的例子：

| 样本 | 实际标签 | 预测概率 |
|------|----------|----------|
| 1    | 1        | 0.9      |
| 2    | 0        | 0.8      |
| 3    | 1        | 0.7      |
| 4    | 0        | 0.6      |
| 5    | 1        | 0.5      |
| 6    | 0        | 0.4      |
| 7    | 1        | 0.3      |
| 8    | 0        | 0.2      |

#### 阈值为 0.5 时：

- 分类结果：样本 1, 2, 3, 4, 5 被预测为正类，样本 6, 7, 8 被预测为负类。
- 混淆矩阵：
  - 真正例（TP）：样本 1, 3, 5（实际为正类且预测为正类）。
  - 假正例（FP）：样本 2, 4（实际为负类但预测为正类）。
  - 真负例（TN）：样本 6, 8（实际为负类且预测为负类）。
  - 假负例（FN）：样本 7（实际为正类但预测为负类）。

计算 TPR 和 FPR：

- TPR = \(\frac{3}{4} = 0.75\)
- FPR = \(\frac{2}{4} = 0.5\)

#### 阈值为 0.7 时：

- 分类结果：样本 1, 2, 3 被预测为正类，样本 4, 5, 6, 7, 8 被预测为负类。
- 混淆矩阵：
  - 真正例（TP）：样本 1, 3（实际为正类且预测为正类）。
  - 假正例（FP）：样本 2（实际为负类但预测为正类）。
  - 真负例（TN）：样本 4, 5, 6, 8（实际为负类且预测为负类）。
  - 假负例（FN）：样本 7（实际为正类但预测为负类）。

计算 TPR 和 FPR：

- TPR = \(\frac{2}{4} = 0.5\)
- FPR = \(\frac{1}{4} = 0.25\)

通过上述例子可以看出，调整阈值会影响 TPR 和 FPR 的值。绘制 ROC 曲线可以帮助我们直观地了解模型在不同阈值下的表现，从而选择最佳的阈值来平衡模型的识别能力和误识别率。

希望这些解释和例子能帮助你更好地理解为什么选择 TPR 和 FPR，以及它们与阈值的关系。如果还有任何问题，请告诉我。



### LAMBADA（Paperno等，2016年）

- **任务**：预测句子的最后一个词。
- **动机**：解决该任务需要建模长距离依赖关系。

#### 适应
- LAMBADA 本质上已经是一个语言建模任务，因此我们可以直接要求语言模型完成句子的最后一个词。
- 问题：语言模型不知道它应该生成句子的最后一个词。
- 解决方案：将其更明确地框架为输入-输出映射，并使用附加示例进行上下文学习（演示）：

填空示例：
```
Alice was friends with Bob. Alice went to visit her friend ___.
```
正确答案是：Bob

```
She held the torch in front of her.
She caught her breath.
“Chris? There's a step.”
“What?”
“A step. Cut in the rock. About fifty feet ahead.” She moved faster. They both moved faster. “In fact,” she said, raising the torch higher, “there's more than a ___.”
```
正确答案是：step

#### 结果
GPT-3 在这个任务上的表现比之前的最新技术（基于GPT-2）好得多。

模型 | 困惑度
--- | ---
GPT-3（少样本） | 1.92
最新技术 | 8.63

请参见[排行榜](https://leaderboard.allenai.org/)获取最新结果。

### HellaSwag（Zellers等，2019年）

- **动机**：评估模型执行常识推理的能力
- **任务**：从选项列表中选择最合适的句子补全

#### 适应
这是一个多项选择任务，所以最自然的做法是对每个候选答案进行评分，并预测“最佳”答案（演示）：

制作蛋糕：展示了几根蛋糕棒。一个女人和女孩在厨房里展示如何制作蛋糕棒。她们 ${answer}

其中，${answer} 是以下之一：
1. 烤它们，然后装饰。
2. 在放到盘子上时尝尝。
3. 在锅里涂上糖霜。
4. 开始装饰蛋糕。

如何根据问题对候选答案 y 进行评分？没有原则上的答案，但这里有一些启发：

1. **未归一化的概率**：
\[ \text{score}(x, y) = p(x, y) \]
问题在于未归一化的概率对短答案有偏向（演示）。

2. **长度归一化的概率**：
\[ \text{score}(x, y) = \frac{p(x, y)}{\text{num-tokens}(y)} \]
这解决了长度偏向。然而，给定两个相同长度的答案，模型仍可能更倾向于更常见的实体。

3. **频率归一化的概率**：
\[ \text{score}(x, y) = \frac{p(y \mid x)}{p(y \mid x_0)} \]
其中，$x_0$ 是一个中性字符串，如 Answer:。这降低了碰巧常见的答案的分数（如 John）。比较[演示](https://demo1)和[演示](https://demo2)。

#### 结果
GPT-3 接近但未超越最新技术：

模型 | 准确率
--- | ---
最新技术 | 85.6
GPT-3 | 79.3

然而，最新技术使用了HellaSwag训练集上的微调，因此GPT-3在没有任何特定任务训练数据的情况下接近最新技术还是令人印象深刻的。

请参见[排行榜](https://leaderboard.allenai.org/)获取最新结果。

### 问答

我们现在考虑（闭卷）问答，其中输入是一个问题，输出是答案。语言模型必须在没有查阅数据库或一组文档（我们将考虑阅读理解任务）的情况下“知道”答案。

输入：Burne Hogarth 建立了哪所学校？
输出：视觉艺术学院

### TriviaQA（Joshi等，2017年）

- **任务**：给定一个琐事问题，生成答案
- **数据集**：原始数据集是从琐事爱好者收集的，并作为挑战阅读理解（开卷）使用，但我们将其用于（闭卷）问答。

#### 适应
我们根据训练实例（如果有）和问题定义一个提示，并将完成的部分作为预测答案（演示）：

```
Q: ‘Nude Descending A Staircase’ is perhaps the most famous painting by which 20th century artist?
A: Marcel Duchamp
```

#### 结果
模型 | 准确率
--- | ---
RAG | 68.0
GPT-3（零样本） | 64.3
GPT-3（少样本） | 71.2




---
理解你的观点，这里确实是使用概率分布来评估候选答案，但频率归一化的作用还是有它的意义的。让我们详细解释一下：

### 评分方法的意义

1. **未归一化的概率 (Unnormalized probability)**：
   \[ \text{score}(x, y) = p(x, y) \]
   这种方法直接使用候选答案的联合概率。问题在于它对短答案有偏向。短答案因为更简单，联合概率较高，可能会被模型高估。

2. **长度归一化的概率 (Length-normalized probability)**：
   \[ \text{score}(x, y) = \frac{p(x, y)}{\text{num-tokens}(y)} \]
   这种方法通过答案的长度（即标记数）对概率进行归一化，从而解决了长度偏向的问题。然而，即使长度相同，模型仍可能更倾向于选择更常见的实体。

3. **频率归一化的概率 (Frequency-normalized probability)**：
   \[ \text{score}(x, y) = \frac{p(y \mid x)}{p(y \mid x_0)} \]
   其中，\( x_0 \) 是一个中性字符串，如 "Answer:"。这种方法通过将候选答案的概率与在中性上下文中的概率进行比较来降低常见答案的分数。例如，对于常见的答案如 "John"，这将降低它们的分数。

### 为什么频率归一化有用

虽然频率归一化可能看起来多此一举，但它的作用在于**减少模型对常见答案的偏向**。在真实任务中，特别是常识推理或知识问答，常见的词汇或实体（如 "John"、"Smith"、"Apple"）可能会经常出现，如果不进行频率归一化，这些常见词汇会占据较高的概率，导致模型选择偏向这些常见词汇，而非真正正确的答案。

### 例子

假设我们有这样一个任务，选择最适合的答案：

```
问题: What is the capital of France?
候选答案: 
1. John
2. Apple
3. Paris
4. Red
```

未归一化的概率可能会给出：

```
p(John) = 0.2
p(Apple) = 0.15
p(Paris) = 0.05
p(Red) = 0.1
```

在这种情况下，虽然 "Paris" 是正确答案，但由于它出现频率较低，模型可能会选择 "John" 或 "Apple"。

通过频率归一化：

```
p(John | "Answer:") = 0.25
p(Apple | "Answer:") = 0.2
p(Paris | "Answer:") = 0.05
p(Red | "Answer:") = 0.1

频率归一化的分数:
score(John) = \frac{0.2}{0.25} = 0.8
score(Apple) = \frac{0.15}{0.2} = 0.75
score(Paris) = \frac{0.05}{0.05} = 1
score(Red) = \frac{0.1}{0.1} = 1
```

这样，"Paris" 的分数更高，因为它的出现频率在中性上下文中较低，因此得到的分数会更高。

### 结论

频率归一化虽然看似多余，但在处理常识推理和知识问答任务时，它能够有效减少模型对常见答案的偏向，提高模型的准确性。因此，频率归一化在某些特定任务中仍然是有意义的。


---
### Fine-tuning 和 Probe 的优劣比较

#### Fine-tuning（微调）

**优点**：

1. **适应性强**：
   - 通过在特定任务上进一步训练预训练模型，微调能够适应该任务的特定需求，从而提升模型的性能。

2. **性能提升**：
   - 通过微调，可以调整模型的所有参数，使其在特定任务上表现更好。特别是在有大量标注数据的情况下，微调后的模型通常比使用嵌入特征的模型表现更优。

3. **全面利用预训练模型**：
   - 微调方法允许模型的所有层级和参数参与训练，全面利用预训练模型捕捉到的语言特征和模式。

**缺点**：

1. **计算资源需求大**：
   - 微调大型预训练模型需要大量的计算资源和时间，尤其是对于具有数亿参数的模型。

2. **容易过拟合**：
   - 在标注数据较少的情况下，微调大型模型可能会导致过拟合，即模型在训练集上表现很好，但在测试集或实际应用中表现不佳。

3. **复杂性高**：
   - 微调过程较为复杂，需要仔细调整超参数和训练策略，以避免过拟合和欠拟合。

#### Probe（探测）

**优点**：

1. **利用预训练的强大能力**：
   - 探测方法利用预训练模型的嵌入作为特征，这些嵌入已经在大规模数据上训练，捕捉了丰富的语言模式和语义信息。

2. **简单高效**：
   - 使用预训练模型的嵌入作为特征，然后训练一个新的小模型（如线性分类器或简单的神经网络），这种方法比直接微调预训练模型更简单高效，所需的计算资源和时间较少。

3. **适用于小数据集**：
   - 对于只有少量标注数据的任务，探测方法可以有效避免过拟合。通过使用嵌入特征并结合简单模型，可以在小数据集上获得良好表现。

**缺点**：

1. **性能上限受限**：
   - 由于探测方法只利用预训练模型的固定嵌入，无法对预训练模型的参数进行调整，因此在某些任务上，性能可能不如经过微调的模型。

2. **任务适应性较低**：
   - 探测方法主要依赖预训练模型捕捉到的通用语言特征，对于需要特定任务知识的场景，其适应性较低。

3. **信息损失**：
   - 预训练模型的嵌入可能无法完全捕捉输入数据的所有信息，在使用嵌入作为特征时，可能会丢失一些细节信息，影响模型的表现。

### 总结

- **Fine-tuning** 更适合在有大量标注数据和充足计算资源的情况下使用，可以充分利用预训练模型的全部潜力，达到更高的性能。
- **Probe** 更适合在标注数据较少或计算资源有限的情况下使用，可以利用预训练模型的嵌入特征，快速构建一个表现良好的模型。

选择哪种方法，主要取决于具体任务的数据规模、计算资源以及对模型性能的要求。