### 图片详细解释

#### Prompt Tuning [Lester et al., 2021]

**简介**：
Prompt Tuning是一种专门为T5模型（一个编码器-解码器架构）开发的文本分类任务的技术。

#### 主要内容：

1. **背景**：
   - **Prompt Tuning**：受到推理基础适应中的prompt设计/工程的启发，Prompt Tuning在输入中添加了 \( k \) 个可学习的、连续的token embedding（这定义了 \( \Gamma \)）。因此，输入长度现在为 \( L' = L + k \)，并在标记的任务数据上训练这个新输入。整个预训练语言模型是被冻结的。

2. **Scaling的影响**：
   - **Scaling（扩展）改进了Prompt Tuning**：随着冻结语言模型的规模变大，Prompt Tuning的性能变得更具竞争力，接近于完全微调（“model tuning”）。

3. **学习到的prompt embedding初始化策略**：
   - **随机词汇表单词的embedding**
   - **类标签词的embedding**
   - **随机初始化**：效果不好

#### 图表分析：

**SuperGLUE Score与模型参数量的关系图**：

- **横轴**：模型参数量（以对数尺度表示）
- **纵轴**：SuperGLUE评分

**不同曲线的含义**：
- **Model Tuning**（模型微调）：橙色和红色曲线分别表示单任务和多任务的模型微调方法，显示出随着模型参数量增加，性能逐渐提升。
- **Prompt Design**（Prompt设计）：蓝色曲线表示手工设计的Prompt方法，性能随着模型参数量增加而提升，但明显低于模型微调和Prompt Tuning。
- **Prompt Tuning**（Prompt微调）：绿色曲线表示Prompt Tuning方法，显示出较好的性能，随着模型参数量增加，性能逐渐逼近完全微调的效果。

### 详细解释各部分内容：

#### Prompt Tuning方法

**开发背景**：
- 针对T5模型设计，适用于文本分类任务。
- 在推理基础适应（inference-based adaptation）中的prompt设计/工程中获得启发。

**技术细节**：
- 在输入序列中添加 \( k \) 个可学习的token embedding，形成新的输入序列长度 \( L' = L + k \)。
- 这些额外的token embedding在训练过程中被学习，而整个预训练语言模型被冻结，不进行更新。

**扩展（Scaling）的影响**：
- 随着模型参数量增加，Prompt Tuning方法的性能提升接近于完全微调（model tuning）。
- 大规模的冻结语言模型（如10亿参数以上）下，Prompt Tuning表现尤为出色，显示出其作为一种高效调整模型的有效方法。

#### 初始化策略

**学习到的prompt embedding初始化**：
1. **随机词汇表单词的embedding**：使用随机选择的词汇表单词初始化embedding，效果较好。
2. **类标签词的embedding**：使用分类任务中的类标签词初始化embedding，效果较好。
3. **随机初始化**：完全随机初始化，效果不好，说明需要一定的初始信息来指导prompt embedding的学习。

#### 图表说明

**性能比较**：
- **Model Tuning**（模型微调）方法在所有模型参数量下表现最佳，但需要更多的计算资源和时间。
- **Prompt Tuning**方法在大模型下（参数量超过10亿）表现接近于完全微调，显示出其在大规模模型中的优势。
- **Prompt Design**方法虽然性能有所提升，但明显低于Prompt Tuning和Model Tuning。

**总结**：
Prompt Tuning通过添加可学习的token embedding，并在冻结的预训练语言模型上进行训练，显示出在大规模模型中的有效性和高效性。通过合理的初始化策略，可以进一步提升Prompt Tuning的性能，使其在大模型下接近于完全微调的效果。

---

这三种方法（Model Tuning、Prompt Tuning 和 Prompt Design）在对预训练语言模型进行适应和微调时有不同的策略和要求。下面详细解释这三种方法的区别：

### 1. Model Tuning（模型微调）

**定义**：
- 直接对整个预训练模型进行微调，包括所有的模型参数。

**方法**：
- 训练过程中，所有模型参数都参与优化，模型根据任务数据进行全面调整。

**优点**：
- 通常在所有模型参数量下表现最佳，因为模型可以完全适应新的任务数据。
- 充分利用模型的容量和预训练知识。

**缺点**：
- 需要大量的计算资源和时间，因为所有参数都需要更新。
- 对硬件和内存要求高，特别是在处理大规模模型时。

### 2. Prompt Tuning（Prompt 微调）

**定义**：
- 只对输入的Prompt部分进行微调，而冻结预训练模型的所有参数。

**方法**：
- 在输入序列中添加 \( k \) 个可学习的、连续的token embedding（prompt embedding）。
- 训练过程中，仅优化这些新增的prompt embedding，预训练模型的参数保持不变。

**优点**：
- 计算资源需求较少，因为只需微调少量的prompt embedding参数。
- 更快的训练速度和更低的内存消耗。
- 在大规模模型（参数量超过10亿）下表现接近于完全微调，显示出其在大模型中的优势。

**缺点**：
- 在小规模模型中性能可能不如完全微调，因为仅调整prompt部分可能不足以完全适应新任务。
- 初始化策略对性能影响较大，需要选择合适的初始化方法。

### 3. Prompt Design（Prompt 设计）

**定义**：
- 使用手工设计的prompt来引导预训练模型适应新任务，而不进行任何参数的微调。

**方法**：
- 根据任务要求，设计一个适当的文本提示（prompt），并将其与输入数据结合。
- 模型通过这些手工设计的prompt进行推理。

**优点**：
- 不需要额外的训练和计算资源，因为不进行参数优化。
- 可以快速应用于预训练模型，适用于一些简单或特定的任务场景。

**缺点**：
- 性能通常低于Prompt Tuning和Model Tuning，因为仅依赖手工设计的prompt可能无法充分利用模型的预训练知识。
- 需要精心设计prompt，且不同任务可能需要不同的prompt设计。

### 总结

**Model Tuning**：对整个模型进行微调，性能最佳，但资源消耗大。

**Prompt Tuning**：仅微调输入的prompt部分，在大模型下性能接近完全微调，资源消耗较少，适合大规模模型。

**Prompt Design**：使用手工设计的prompt，不进行任何微调，资源消耗最少，但性能通常低于前两者。

这些方法在适应不同任务和资源条件下，各有优劣，选择时需根据具体需求和约束进行权衡。

---

### Prefix Tuning [Li and Liang, 2021]

#### 背景和定义

**开发背景**：
- Prefix Tuning 是为语言生成任务开发的，主要应用于BART和GPT-2模型上。

**方法概述**：
- 对于预先添加到输入中的 \( k \) 个位置，在每个注意力层（attention layer）上连接额外的可学习的权重（keys 和 values）。
- 不同于Prompt Tuning，只调整可学习的输入向量，Prefix Tuning调整的是每个注意力层的keys和values。

#### Prefix Tuning的定义

**注意力操作的一般定义**：
\[ \text{Attn-op}(Q, K, V) = V \text{softmax}\left(\frac{K^\top Q}{\sqrt{d}}\right) \]

其中：
- \( K \in \mathbb{R}^{d \times L'} \)：keys矩阵
- \( V \in \mathbb{R}^{d \times L'} \)：values矩阵
- \( Q \in \mathbb{R}^{d \times L} \)：queries矩阵

**自注意力（Self-attention）情况下**：
- \( L' = L \)
- \( K = W_{\text{key}} x_{1:L} \)
- \( V = W_{\text{value}} x_{1:L} \)
- \( Q = W_{\text{query}} x_{1:L} \)

其中，\( W_{\text{key}} \)、\( W_{\text{value}} \) 和 \( W_{\text{query}} \) 是可学习的权重矩阵。

#### Prefix Tuning的具体计算

对于注意力头 \( i \)，Prefix Tuning 计算带有更大 \( L' = L + k \) 的注意力：
- 通过将可学习的权重 \( P_{\text{key}}^{(i)} \) 和 \( P_{\text{value}}^{(i)} \) 连接到key和value上：
  \[
  K_{\text{prefix}} = \left[ P_{\text{key}}^{(i)}, K \right]
  \]
  \[
  V_{\text{prefix}} = \left[ P_{\text{value}}^{(i)}, V \right]
  \]

注意力头 \( i \) 的计算公式：
\[ \text{head}_i = \text{Attn-op}(Q, K_{\text{prefix}}, V_{\text{prefix}}) \]

其中，\( Q \) 与常规自注意力中的 \( Q = W_{\text{query}} x_{1:L} \) 相同。

#### 训练参数

所有层的训练参数有助于模型的性能提升：
- **Prompt Tuning v2**：Prompt Tuning的全层版本
- 所有层的参数似乎都有助于文本分类和生成任务

### 详细解释

#### Prefix Tuning方法

1. **目标**：
   - 为了解决生成任务中的特定问题，Prefix Tuning 通过调整每个注意力层的keys和values来引导模型更好地生成目标序列。

2. **方法**：
   - 在每个注意力层，除了原有的keys和values外，还添加了 \( k \) 个可学习的权重矩阵 \( P_{\text{key}} \) 和 \( P_{\text{value}} \)，并将它们与原始的keys和values进行连接，形成 \( K_{\text{prefix}} \) 和 \( V_{\text{prefix}} \)。
   - 这些额外的权重在训练过程中被优化，以提高生成任务的性能。

3. **计算过程**：
   - 自注意力机制中的keys、values和queries通过权重矩阵进行转换，形成 \( K \)、\( V \) 和 \( Q \)。
   - Prefix Tuning将额外的可学习权重 \( P_{\text{key}} \) 和 \( P_{\text{value}} \) 连接到原始的 \( K \) 和 \( V \) 上，形成新的keys和values，即 \( K_{\text{prefix}} \) 和 \( V_{\text{prefix}} \)。
   - 最终，通过注意力操作公式计算新的注意力头 \( \text{head}_i \)。

#### 优势

- **灵活性**：通过在每层注意力中添加额外的可学习权重，Prefix Tuning可以灵活地调整模型生成序列的能力。
- **高效性**：相比于全模型微调，Prefix Tuning只调整特定的前缀权重，减少了计算资源和训练时间。
- **扩展性**：随着模型参数量的增加，Prefix Tuning可以充分利用大模型的优势，提高生成任务的性能。

#### 结论

Prefix Tuning 通过在每层注意力中添加额外的可学习权重，实现了在不完全微调模型的情况下，提高生成任务性能的目的。与Prompt Tuning相比，Prefix Tuning提供了更细粒度的控制，适用于需要高灵活性和高效性的生成任务。

---

### 图片详细解释

### 第一张图片：Adapter Tuning [Houlsby et al., 2019]

#### Adapter Tuning

**定义**：
- 在每个（冻结的）Transformer层之间添加一个新的学习“瓶颈”层（适配器）。

**方法**：
- 适配器通常是操作序列中每个元素的两层残差网络：

  \[
  \text{Adapter}(x) = x + W_{\text{up}} \sigma(W_{\text{down}} x)
  \]

  其中，\( W_{\text{down}} \in \mathbb{R}^{d \times r} \) 和 \( W_{\text{up}} \in \mathbb{R}^{r \times d} \) 是学习的权重，将 \( x \) 投影到瓶颈维度 \( r \)，然后再投影回到维度 \( d \)，\( \sigma \) 是非线性激活函数。

- **注意**：轻量级微调的表现力复杂，因为表现力与特定的预训练语言模型有关——如果预训练语言模型有权重为0，那么prompt/prefix微调将不起作用。

#### Parallelization over Prefixes/Prompts

**场景**：
- 假设我们要为 \( N \) 个用户部署个性化模型。

**方法**：
- 使用Prefix Tuning，我们可以存储 \( N \) 个前缀，每个用户一个。
- 在一个minibatch中为每个用户并行运行个性化模型，通过在minibatch的每个输入中添加相应的用户特定前缀。

#### Robustness of Lightweight Fine-tuning

**优势**：
- 轻量级微调方法倾向于提高分布外（OOD）性能，与完全微调相比，例如在不同主题或领域的文本上。

### 第二张图片：Prefix Tuning的性能提升

#### 实验结果

**表格解释**：
- 比较了模型微调和Prompt Tuning在不同数据集上的性能。指标是F1分数。

**数据集**：
- SQuAD, TextbookQA, BioASQ, RACE, RE, DuoRC, DROP

**性能对比**：
- Prefix Tuning在大多数数据集上优于完全微调，特别是在TextbookQA（+12.5）和BioASQ（+1.2）上。

**结论**：
- Prefix Tuning在分布外（OOD）准确性上有显著提升。例如，在XSUM摘要任务中，模型在新闻文章上微调，在体育（新闻到体育）或{world, UK, business}文章上训练并在{health, technology}文章上测试。

**XSUM任务**：
- 使用的指标是ROUGE-L，一个基于与参考摘要匹配的自动评估指标。Prefix Tuning在分布外任务上的表现通常比完全微调稍差。

### 第三张图片：轻量级微调方法总结

#### 总结

**Freeze（冻结）**：
- 灰色：冻结整个或大部分语言模型。

**Optimize（优化）**：
- 蓝色：每个任务中变化的部分是少量的附加参数（<1%的参数）。

**Methods（方法）**：
- Prompt Tuning, Prefix Tuning, Adapter Tuning, 以及其他方法（如LoRA, BitFit等）。

### 总结

- **Adapter Tuning**：通过在每个Transformer层之间添加适配器层来进行微调，仅更新适配器层的参数，预训练模型参数保持冻结。
- **Parallelization**：可以通过存储用户特定的前缀，实现个性化模型的并行化运行。
- **Robustness**：轻量级微调方法（如Prompt Tuning）在分布外任务上表现优异，尤其在特定领域的摘要任务中。
- **性能对比**：Prefix Tuning在大多数数据集上优于完全微调，特别是在需要分布外泛化能力的任务中。

这些方法通过冻结大部分模型参数，只更新少量的附加参数，实现了高效的微调，节省了计算资源，同时提高了模型在不同任务和数据集上的性能。

---

### Adapter Tuning和Prompt Tuning的区别

#### 1. Adapter Tuning

**定义**：
- Adapter Tuning是在每个（冻结的）Transformer层之间添加一个新的“瓶颈”层（适配器），用于调整模型。

**方法**：
- 适配器通常是一个两层的残差网络，其公式如下：
  \[
  \text{Adapter}(x) = x + W_{\text{up}} \sigma(W_{\text{down}} x)
  \]
  其中：
  - \( W_{\text{down}} \in \mathbb{R}^{d \times r} \) 是将输入 \( x \) 投影到一个较小的瓶颈维度 \( r \) 的权重矩阵。
  - \( W_{\text{up}} \in \mathbb{R}^{r \times d} \) 是将瓶颈表示投影回原始维度 \( d \) 的权重矩阵。
  - \( \sigma \) 是非线性激活函数（例如ReLU）。

**优点**：
- **模块化设计**：适配器层可以容易地添加到现有的Transformer架构中，而无需修改原始模型结构。
- **参数高效**：仅需要训练适配器层的少量参数，大部分预训练模型参数保持冻结。
- **灵活性**：适配器层可以根据任务的需要进行调整，使模型在多个任务之间具有较好的适应性。

**缺点**：
- **复杂性增加**：引入适配器层增加了模型的复杂性，需要额外的计算资源来训练适配器层。

#### 2. Prompt Tuning

**定义**：
- Prompt Tuning通过在输入序列中添加可学习的前缀向量来调整模型，预训练语言模型的所有参数保持冻结。

**方法**：
- 在输入序列前添加 \( k \) 个可学习的前缀向量（prompt embedding），并在任务数据上进行训练。
- 公式表示为：将原始输入序列 \( x_{1:L} \) 变为 \( [P_{1:k}, x_{1:L}] \)，其中 \( P_{1:k} \) 是前缀向量。

**优点**：
- **简单高效**：仅需要训练前缀向量，参数量极少，计算资源需求低。
- **快速部署**：可以快速应用到不同的任务和数据集上，无需修改预训练模型。
- **参数高效**：相比完全微调，只需要更新少量的前缀向量参数。

**缺点**：
- **上下文依赖性**：前缀向量的效果依赖于预训练模型的上下文表示，可能在某些任务上表现不如完全微调。
- **性能不稳定**：在某些任务上，尤其是输入数据分布变化较大的任务中，性能可能不如完全微调。

### 总结

**Adapter Tuning**：
- **操作位置**：在每个Transformer层之间添加适配器层。
- **参数量**：需要训练适配器层的参数，通常比Prompt Tuning的参数量多。
- **灵活性**：适配器层的引入使得模型在多个任务之间具有较好的适应性。
- **复杂性**：增加了模型的复杂性和计算资源需求。

**Prompt Tuning**：
- **操作位置**：在输入序列前添加可学习的前缀向量。
- **参数量**：仅需要训练前缀向量，参数量极少。
- **灵活性**：可以快速应用于不同任务，参数高效。
- **性能**：在某些任务上，性能可能不如完全微调，尤其是输入数据分布变化较大的任务。

这两种方法各有优缺点，选择哪种方法取决于具体任务的需求、计算资源的可用性以及对模型性能的要求。在实际应用中，可以根据任务特性和资源条件选择最合适的方法。

---


### Adapter Tuning [Houlsby et al., 2019]

#### Adapter Tuning 详细解释

**定义**：
- 在每个（冻结的）Transformer层之间添加一个新的学习“瓶颈”层（适配器）。

**方法**：
- 适配器通常是一个两层的残差网络，其公式如下：
  \[
  \text{Adapter}(x) = x + W_{\text{up}} \sigma(W_{\text{down}} x)
  \]
  其中：
  - \( W_{\text{down}} \in \mathbb{R}^{d \times r} \)：将输入 \( x \) 投影到一个较小的瓶颈维度 \( r \) 的权重矩阵。
  - \( W_{\text{up}} \in \mathbb{R}^{r \times d} \)：将瓶颈表示投影回原始维度 \( d \) 的权重矩阵。
  - \( \sigma \)：非线性激活函数（例如ReLU）。

**举例说明**：
- 假设我们有一个预训练的Transformer模型用于文本分类任务，该模型有12层，每层的输入和输出维度均为768。
- 通过Adapter Tuning，我们在每层Transformer层之间添加一个适配器层，适配器层的瓶颈维度 \( r \) 设为64。
- 对于每个输入 \( x \)（维度为768），适配器层首先通过 \( W_{\text{down}} \) 投影到瓶颈维度（64），然后通过非线性激活函数 \( \sigma \)（例如ReLU），再通过 \( W_{\text{up}} \) 投影回原始维度（768），并与输入 \( x \) 相加，形成最终的输出。

**具体操作**：
1. 输入 \( x \)（维度768）。
2. \( W_{\text{down}} x \)：将输入投影到瓶颈维度64。
3. \( \sigma(W_{\text{down}} x) \)：通过非线性激活函数。
4. \( W_{\text{up}} \sigma(W_{\text{down}} x) \)：将瓶颈表示投影回原始维度768。
5. 最终输出：\( x + W_{\text{up}} \sigma(W_{\text{down}} x) \)。

#### Parallelization over Prefixes/Prompts 详细解释

**场景**：
- 假设我们要为 \( N \) 个用户部署个性化模型。

**方法**：
- 使用Prefix Tuning，我们可以存储 \( N \) 个前缀，每个用户一个。
- 在一个minibatch中为每个用户并行运行个性化模型，通过在minibatch的每个输入中添加相应的用户特定前缀。

**举例说明**：
- 假设我们有一个聊天机器人系统，需要为1000个用户提供个性化的回答。
- 使用Prefix Tuning，我们为每个用户生成一个特定的前缀。这些前缀是可学习的，并在训练过程中根据用户的对话历史进行优化。
- 在实际运行时，我们可以在一个minibatch中并行处理多个用户的请求。每个用户的输入序列前面都添加相应的前缀，从而实现个性化的响应。

**具体操作**：
1. 对于每个用户 \( u_i \)，生成一个特定的前缀 \( P_i \)。
2. 用户 \( u_i \) 的输入序列 \( x_i \) 变为 \( [P_i, x_i] \)。
3. 在一个minibatch中并行处理所有用户的输入序列 \( [P_1, x_1], [P_2, x_2], \ldots, [P_N, x_N] \)。
4. 模型根据每个用户的前缀和输入序列生成个性化的响应。

### 对比总结

**Adapter Tuning**：
- 在Transformer层之间添加适配器层，适配器层由两个线性层和一个非线性激活函数组成。
- 适配器层仅占用少量参数，并且可以在不改变原始预训练模型的情况下进行训练。
- 适用于需要调整模型内部表示的任务，通过增加模型的参数容量，提高任务的适应性。

**Prefix Tuning**：
- 在输入序列前添加可学习的前缀向量，通过调整前缀向量来引导模型生成期望的输出。
- 前缀向量在训练过程中被优化，预训练模型的参数保持不变。
- 适用于需要快速部署和微调的任务，特别是需要处理个性化或特定上下文的场景。

通过以上解释和举例，希望能帮助你更好地理解Adapter Tuning和Prefix Tuning的区别和应用场景。


---

### Prompt Tuning（Prompt 微调）

#### 定义

Prompt Tuning是一种通过在输入序列前添加可学习的前缀向量（prompt embedding）来调整模型的方法。预训练模型的所有参数保持冻结，只优化这些前缀向量。

#### 方法

1. **输入序列扩展**：将原始输入序列 \( x_{1:L} \) 扩展为 \( [P_{1:k}, x_{1:L}] \)，其中 \( P_{1:k} \) 是可学习的前缀向量。
2. **训练过程**：在任务数据上训练时，只优化前缀向量 \( P_{1:k} \)，预训练模型的参数保持不变。

#### 举例说明

假设我们有一个预训练的GPT-2模型，并且我们希望它在一个特定的分类任务上进行微调，例如情感分析任务。

**步骤**：

1. **定义前缀向量**：首先，我们定义一个长度为 \( k \) 的前缀向量 \( P_{1:k} \)。这些向量初始化为随机值或其他合适的初始值。

2. **扩展输入序列**：对于每个输入文本，例如“今天的天气很好”，首先将其转化为输入序列 \( x \)：
   \[
   x = [\text{今天, 的, 天气, 很, 好}]
   \]
   然后在输入序列前添加前缀向量：
   \[
   \text{新输入序列} = [P_{1}, P_{2}, \ldots, P_{k}, \text{今天, 的, 天气, 很, 好}]
   \]

3. **输入模型**：将新输入序列输入到预训练的GPT-2模型中。由于前缀向量 \( P_{1:k} \) 是可学习的，它们会影响模型的注意力机制和生成的输出。

4. **训练**：在训练过程中，优化前缀向量 \( P_{1:k} \) 以最小化分类任务的损失。例如，如果这是一个情感分析任务，我们希望模型正确地输出“积极”或“消极”的情感标签。

5. **推理**：在推理阶段，对于新的输入文本，只需要将前缀向量添加到输入序列前，然后将扩展后的输入序列输入到模型中，模型将根据优化过的前缀向量生成分类结果。

#### 具体示例

**任务**：情感分析任务

**模型**：预训练的GPT-2

**输入文本**：今天的天气很好

**步骤**：

1. 定义一个长度为3的前缀向量 \( P_{1:3} \)：
   \[
   P_{1:3} = [P_1, P_2, P_3]
   \]
   
2. 将输入文本转化为输入序列并添加前缀向量：
   \[
   \text{新输入序列} = [P_1, P_2, P_3, \text{今天, 的, 天气, 很, 好}]
   \]

3. 输入扩展后的序列到GPT-2模型中。

4. 在训练过程中，优化前缀向量 \( P_{1:3} \) 以最小化情感分析的分类损失。

5. 在推理阶段，对于新输入文本，如“我今天很高兴”，重复上述步骤，使用优化后的前缀向量生成分类结果。

#### 优点

- **计算效率高**：只需优化少量的前缀向量，参数量少，计算资源需求低。
- **快速部署**：可以快速应用到不同的任务和数据集上，无需修改预训练模型。
- **适应性强**：前缀向量可以根据特定任务进行调整，提高模型在特定任务上的性能。

#### 总结

Prompt Tuning通过在输入序列前添加可学习的前缀向量，使预训练模型在特定任务上表现更好。它的高效性和快速部署能力使其成为一种非常有用的微调方法，尤其适用于需要处理个性化或特定上下文的任务。

---

Prompt Tuning 和 Prefix Tuning 是两个相关但不同的技术，它们的主要区别在于它们调整模型的方式和位置。下面详细解释这两种方法的区别和联系。

### Prompt Tuning

**定义**：
- 在输入序列前添加可学习的前缀向量（prompt embedding）。

**方法**：
- 将输入序列 \( x_{1:L} \) 扩展为 \( [P_{1:k}, x_{1:L}] \)，其中 \( P_{1:k} \) 是可学习的前缀向量。
- 在训练过程中，只优化这些前缀向量，预训练模型的参数保持不变。

**应用场景**：
- 适用于文本分类、情感分析等任务，通过在输入序列前添加前缀向量来引导模型生成期望的输出。

### Prefix Tuning

**定义**：
- 在每个注意力层（attention layer）添加可学习的前缀向量（prefix embedding）。

**方法**：
- 在每个Transformer层的注意力计算中，添加额外的可学习的keys和values前缀向量。
- 将输入序列前的前缀向量 \( P_{1:k} \) 扩展到每个注意力层中，形成新的keys和values矩阵。

**应用场景**：
- 适用于语言生成任务，如摘要生成、翻译等，通过在每个注意力层添加前缀向量来调整注意力机制。

### 主要区别

#### 位置和方式

- **Prompt Tuning**：在输入序列前添加前缀向量，整个前缀向量作为输入的一部分被传递到模型中。只优化输入前缀，预训练模型的其他部分保持不变。
  - **例子**：对于输入序列“今天的天气很好”，在其前添加前缀，形成新输入“[前缀] 今天的天气很好”。

- **Prefix Tuning**：在每个注意力层添加前缀向量，调整每个注意力层的keys和values矩阵。前缀向量在每个注意力计算中起作用。
  - **例子**：对于输入序列“今天的天气很好”，不仅在输入前添加前缀，而且在每个注意力层计算时都加入前缀向量。

#### 计算复杂性

- **Prompt Tuning**：计算复杂性低，只需要优化少量的前缀向量。适用于资源受限的场景。
- **Prefix Tuning**：计算复杂性较高，需要在每个注意力层添加和优化前缀向量。适用于需要更细粒度调整的场景。

#### 表现力

- **Prompt Tuning**：适用于简单的文本分类任务，通过调整输入前缀来引导模型生成特定输出。
- **Prefix Tuning**：适用于复杂的生成任务，通过在每个注意力层中调整前缀向量，提供更强的表现力和灵活性。

### 联系

尽管Prompt Tuning和Prefix Tuning在具体实现和应用上有所不同，但它们都共享一个核心理念：通过添加和优化额外的前缀向量，而不改变预训练模型的参数，来调整模型在特定任务上的表现。这使得它们在微调预训练模型时都具有高效性和灵活性。

### 总结

- **Prompt Tuning**：通过在输入序列前添加前缀向量，适用于文本分类等简单任务。
- **Prefix Tuning**：通过在每个注意力层添加前缀向量，适用于语言生成等复杂任务。

这两种方法根据具体任务和资源限制，可以灵活选择和应用。